{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Task 2 - Minz Won & Marc Siquier\n",
    "This is the code and report for task 2 - ASPMA LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All necesary imports\n",
    "We will use essentia in order to extract MFCCs for all audio tracks and sklearn in order to train and test GMMs and to evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import essentia\n",
    "import os\n",
    "import json\n",
    "import operator\n",
    "import random\n",
    "from essentia.standard import *\n",
    "from essentia import pool\n",
    "import numpy as np\n",
    "from sklearn import mixture\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup working directory\n",
    "Please set-up your inputDir to the genre folder...\n",
    "\n",
    "for example: `inputDir = '/home/user/datasets/genre'`\n",
    "\n",
    "this folder should contain folders named with genre class and inside of it the audios and extracted json with features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputDir = '/home/marcsiq/SMC/aspma-lab/genre'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch all mp3 files.\n",
    "Define a function to fetch files that will be used to also fetch .json\n",
    "\n",
    "__NOTE:__ If you downloaded this from github, audios are not provided, so number of fetched files will be 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mp3 files fetched: 438\n"
     ]
    }
   ],
   "source": [
    "def fetchFiles(inputDir, descExt):\n",
    "    files = []\n",
    "    for path, dname, fnames  in os.walk(inputDir):\n",
    "        for fname in fnames:\n",
    "            if descExt in fname.lower():\n",
    "                files.append((path, fname))\n",
    "    return files\n",
    "\n",
    "mp3files = fetchFiles(inputDir, \".mp3\")\n",
    "print \"Number of mp3 files fetched: \" + str(len(mp3files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and save mfcc for all fetched files\n",
    "__NOTE:__ In order to save time, dont run this cell if mfccs are already extracted in json files.\n",
    "In this cell we compute mfccs for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = Windowing(type = 'hann')\n",
    "# FFT() would return the complex FFT, here we just want the magnitude spectrum\n",
    "spectrum = Spectrum()  \n",
    "mfcc = MFCC()\n",
    "for path, file in mp3files:\n",
    "    file_name, extension = os.path.splitext(file)\n",
    "    file_location = path + \"/\" + file\n",
    "    print file_location\n",
    "\n",
    "    #computing mfcc\n",
    "    loader = essentia.standard.EqloudLoader(filename = file_location)\n",
    "    audio = loader()\n",
    "    pool = essentia.Pool()\n",
    "    for frame in FrameGenerator(audio, frameSize = 2048, hopSize = 512, startFromZero=True):\n",
    "        mfcc_bands, mfcc_coeffs = mfcc(spectrum(w(frame)))\n",
    "        pool.add('lowlevel.mfcc', mfcc_coeffs)\n",
    "        pool.add('lowlevel.mfcc_bands', mfcc_bands)\n",
    "\n",
    "    # saving Mfcc aggregated per audio file\n",
    "    aggrPool = PoolAggregator(defaultStats = [ 'mean', 'var' ])(pool)\n",
    "    YamlOutput(filename = path + \"/\"+ file_name + \".json\", format = \"json\")(aggrPool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch and collect all mfcc.json files\n",
    "Reusing function `fetchFiles` defined in cell 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of json files fetched: 438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcsiq/.local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/marcsiq/.local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/marcsiq/.local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/marcsiq/.local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/marcsiq/.local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/marcsiq/.local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/marcsiq/.local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/marcsiq/.local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/marcsiq/.local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/marcsiq/.local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/marcsiq/.local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/home/marcsiq/.local/lib/python2.7/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "jsonfiles = fetchFiles(inputDir, \".json\")\n",
    "print \"Number of json files fetched: \" + str(len(jsonfiles))\n",
    "al = []\n",
    "mfccs = dict()\n",
    "for path, fname in jsonfiles:\n",
    "    genre_clas = os.path.basename(os.path.normpath(path))\n",
    "    pool = essentia.Pool()\n",
    "    pool = YamlInput(filename = path + \"/\"+ fname, format = \"json\")()\n",
    "    if genre_clas not in mfccs:\n",
    "        mfccs[genre_clas] = []\n",
    "    mfccs[genre_clas].append(pool)\n",
    "    \n",
    "for genre in mfccs:\n",
    "    for pool in mfccs[genre]:\n",
    "        al.append(pool['lowlevel.mfcc.mean'][1:] )\n",
    "\n",
    "normalized = []\n",
    "for mfcc_idx in range(0,12):\n",
    "    normalized.append(preprocessing.normalize([item[mfcc_idx] for item in al]))\n",
    "    \n",
    "id = 0\n",
    "for genre in mfccs:\n",
    "    for idx, pool in enumerate(mfccs[genre]):\n",
    "        mfcc_norm = []\n",
    "        for idx2 in range(12):\n",
    "            mf = [item[id] for item in normalized[idx2]][0]\n",
    "            mfcc_norm.append(mf)\n",
    "\n",
    "        mfccs[genre][idx].add('mfcc_normalized', mfcc_norm)\n",
    "        id += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate dataset into train and test\n",
    "As we separate dataset randomly, results vary for each execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created training and testing sets with the following number of sounds:\n",
      "\tTrain\tTest\tTotal\tClass\n",
      "\t50\t5\t55\thip\n",
      "\t50\t5\t55\trhy\n",
      "\t50\t5\t55\tjaz\n",
      "\t50\t5\t55\tdan\n",
      "\t50\t5\t55\troc\n",
      "\t50\t5\t55\tcla\n",
      "\t49\t5\t54\tpop\n",
      "\t49\t5\t54\tspe\n"
     ]
    }
   ],
   "source": [
    "mfccs_train = dict()\n",
    "mfccs_test = dict()\n",
    "percentage_train = 0.9\n",
    "\n",
    "for class_name, sounds in mfccs.items():\n",
    "    sounds_class = sounds[:]\n",
    "    train_per_class = int(np.ceil(len(sounds_class)*percentage_train))\n",
    "    random.shuffle(sounds_class)\n",
    "    mfccs_train[class_name] = sounds_class[:train_per_class]\n",
    "    mfccs_test[class_name] = sounds_class[train_per_class:]\n",
    "\n",
    "print 'Created training and testing sets with the following number of sounds:\\n\\tTrain\\tTest\\tTotal\\tClass'\n",
    "for class_name in mfccs_train:\n",
    "    training_sounds = mfccs_train[class_name]\n",
    "    testing_sounds = mfccs_test[class_name]\n",
    "    print '\\t%i\\t%i\\t%i\\t%s' % (len(training_sounds), len(testing_sounds), len(mfccs[class_name]), class_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute a GMM with train dataset for each genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gmms = dict()\n",
    "gmms_non = dict()\n",
    "for genre in mfccs_train:\n",
    "    features = []\n",
    "    features_non = []\n",
    "    for pool in mfccs_train[genre]:\n",
    "        #collect mfcc.mean withouth DC value\n",
    "        mfcc = pool['mfcc_normalized'][0]\n",
    "        mfcc_non = pool['lowlevel.mfcc.mean'][1:]\n",
    "        features.append(mfcc)\n",
    "        features_non.append(mfcc_non)\n",
    "        \n",
    "    gmms[genre] = mixture.GaussianMixture(n_components=1)\n",
    "    gmms[genre].fit(features)\n",
    "    gmms_non[genre] = mixture.GaussianMixture(n_components=1)\n",
    "    gmms_non[genre].fit(features_non)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....WITH NORMALIZATION.....\n",
      "\n",
      "Classification report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        cla       1.00      0.60      0.75         5\n",
      "        dan       0.75      0.60      0.67         5\n",
      "        hip       0.57      0.80      0.67         5\n",
      "        jaz       0.44      0.80      0.57         5\n",
      "        pop       0.75      0.60      0.67         5\n",
      "        rhy       0.50      0.40      0.44         5\n",
      "        roc       1.00      0.40      0.57         5\n",
      "        spe       0.71      1.00      0.83         5\n",
      "\n",
      "avg / total       0.72      0.65      0.65        40\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[3 0 0 0 0 0 0 2]\n",
      " [0 3 0 1 1 0 0 0]\n",
      " [0 0 4 1 0 0 0 0]\n",
      " [0 0 0 4 0 1 0 0]\n",
      " [0 1 1 0 3 0 0 0]\n",
      " [0 0 1 2 0 2 0 0]\n",
      " [0 0 1 1 0 1 2 0]\n",
      " [0 0 0 0 0 0 0 5]]\n",
      "\n",
      "\n",
      ".....WITHOUT NORMALIZATION.....\n",
      "\n",
      "Classification report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        cla       1.00      0.60      0.75         5\n",
      "        dan       0.67      0.40      0.50         5\n",
      "        hip       0.57      0.80      0.67         5\n",
      "        jaz       0.44      0.80      0.57         5\n",
      "        pop       0.75      0.60      0.67         5\n",
      "        rhy       0.50      0.40      0.44         5\n",
      "        roc       0.67      0.40      0.50         5\n",
      "        spe       0.71      1.00      0.83         5\n",
      "\n",
      "avg / total       0.66      0.62      0.62        40\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      "[[3 0 0 0 0 0 0 2]\n",
      " [0 2 0 1 1 0 1 0]\n",
      " [0 0 4 1 0 0 0 0]\n",
      " [0 0 0 4 0 1 0 0]\n",
      " [0 1 1 0 3 0 0 0]\n",
      " [0 0 1 2 0 2 0 0]\n",
      " [0 0 1 1 0 1 2 0]\n",
      " [0 0 0 0 0 0 0 5]]\n"
     ]
    }
   ],
   "source": [
    "correct = []\n",
    "predicted = []\n",
    "predicted_non = []\n",
    "for genre in mfccs_test:\n",
    "    for pool in mfccs_test[genre]:\n",
    "        results = dict()\n",
    "        results_non = dict()\n",
    "        for g in gmms:\n",
    "            x = np.array(pool['mfcc_normalized'][0])\n",
    "            x = x.reshape(1,-1)\n",
    "            x_non= np.array(pool['lowlevel.mfcc.mean'][1:])\n",
    "            x_non = x_non.reshape(1, -1)\n",
    "            results[g] = gmms[g].score(x)\n",
    "            results_non[g] = gmms_non[g].score(x_non)\n",
    "            \n",
    "        predicted.append(max(results, key=results.get))\n",
    "        predicted_non.append(max(results_non, key=results_non.get))\n",
    "        correct.append(genre)\n",
    "\n",
    "print \".....WITH NORMALIZATION.....\\n\\nClassification report\\n\"\n",
    "print metrics.classification_report(correct, predicted)\n",
    "print \"Confusion Matrix\\n\"\n",
    "print metrics.confusion_matrix(correct, predicted)\n",
    "\n",
    "print \"\\n\\n.....WITHOUT NORMALIZATION.....\\n\\nClassification report\\n\"\n",
    "print metrics.classification_report(correct, predicted_non)\n",
    "print \"Confusion Matrix\\n\"\n",
    "print metrics.confusion_matrix(correct, predicted_non)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "By running last three cells several times we can see that results vary a lot depending on the random splitting of the dataset into train and test. Some times normalized features work better and some times non-normalized features work better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
