{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART A - Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from freesound import freesound\n",
    "import random\n",
    "import utils\n",
    "from utils.run_entity_linking import spotlight\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Get the API key from http://www.freesound.org/apiv2/apply/ (you'll need Freesound user account)\n",
    "API_KEY='YOUR_API_KEY'\n",
    "c = freesound.FreesoundClient()\n",
    "c.set_token(API_KEY,\"token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Define a number of audio categories and find audio examples from Freesound for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Configure dataset parameters and audio categories\n",
    "DATASET_NAME = 'broad' # Dataset will be saved in a .json file with this name\n",
    "DATASET_CLASSES = {  \n",
    "    # Must be dictionary with structure like {'class name': 'query terms', 'class name 2': 'query terms 2',... }\n",
    "    'Soundscape': 'field-recording',\n",
    "    'Instrument': 'multi-sample',\n",
    "    'Voice': 'voice',\n",
    "    'SoundFX': 'fx sound-fx',\n",
    "}\n",
    "N = 100 # Number of sounds per class\n",
    "N_SOUNDS_PER_USER = 3  # Do not get more than 3 sounds per user\n",
    "\n",
    "# Get sound examples from Freesound\n",
    "dataset = dict()\n",
    "for name, target_query in DATASET_CLASSES.items():\n",
    "    print 'Getting sounds for class %s...' % name,\n",
    "    \n",
    "    # Get first page of results\n",
    "    PAGE_SIZE = 150 # Page size for fs requests\n",
    "    N_PAGES = int((N * 1) / PAGE_SIZE)  # Number of pages to retrieve\n",
    "    fields = \"id,tags,description,username\"\n",
    "    results_pager = c.text_search(\n",
    "        query=target_query,\n",
    "        page_size=PAGE_SIZE,\n",
    "        group_by_pack=1,\n",
    "        fields = \"id,tags,description,username,analysis\",\n",
    "        #descriptors = \"lowlevel.spectral_centroid,sfx.duration\",\n",
    "        )\n",
    "    all_results = results_pager.results\n",
    "\n",
    "    # TIP ON AUDIO FEATURES: you can get also audio features extracted in freesound by passing a 'descriptors' \n",
    "    # parameter in the text_search function and including 'analysis' in the fields list \n",
    "    # (see http://www.freesound.org/docs/api/resources_apiv2.html#response-sound-list):\n",
    "    #\n",
    "    # fields = \"id,tags,description,username,analysis\"\n",
    "    # descriptors = \"lowlevel.spectral_centroid,lowlevel.barkbands.mean\"\n",
    "    #\n",
    "    # e.g.: results_page = c.text_search(query=target_query, ..., fields=fields, descriptors=descriptors)\n",
    "    # ...\n",
    "    \n",
    "    # Get extra pages\n",
    "    for i in range(0, N_PAGES):\n",
    "        if results_pager.count > (i+1) * PAGE_SIZE:\n",
    "            results_pager = results_pager.next_page()\n",
    "            all_results += results_pager.results\n",
    "    \n",
    "    # Get only N sounds max per user\n",
    "    user_sounds_count = dict()\n",
    "    filtered_results = list()\n",
    "    random.shuffle(all_results)  # Shuffle list of sounds (randomise order)\n",
    "    for result in all_results:\n",
    "        if result[\"username\"] in user_sounds_count:\n",
    "            user_sounds_count[result[\"username\"]] += 1\n",
    "        else:\n",
    "            user_sounds_count[result[\"username\"]] = 1\n",
    "        if user_sounds_count[result[\"username\"]] <= N_SOUNDS_PER_USER:\n",
    "            filtered_results.append(result)\n",
    "\n",
    "    # Randomly select N sounds from al results obtained\n",
    "    if len(filtered_results) >= N:\n",
    "        selected_sounds = random.sample(filtered_results, N)\n",
    "        dataset[name] = selected_sounds\n",
    "        print 'selected %i sounds out of %i!' % (len(selected_sounds), len(filtered_results))\n",
    "    else:\n",
    "        print 'not enough sounds were found for current class (%i sounds found).' % len(filtered_results)\n",
    "\n",
    "    # TIP ON KEYWORD EXTRACTION: we could extract some keywords from the textual descriptions using functions\n",
    "    # provided in ELVIS (see https://github.com/sergiooramas/elvis and run_entity_linking.py file in utils folder)\n",
    "    # You can uncomment the example code below to get keywords for each sound (dataset creation will take longer)\n",
    "    \n",
    "    '''\n",
    "    for class_name, sounds in dataset.items():\n",
    "        for sound in sounds:\n",
    "            sound_textual_description = sound['description']\n",
    "            results = spotlight(sound_textual_description.split('\\n'))\n",
    "            keywords = list()\n",
    "            for element in results:\n",
    "                for entity in element['entities']:\n",
    "                    keywords.append(entity['label'])\n",
    "            sound['keywords'] = keywords\n",
    "    '''\n",
    "\n",
    "# Save dataset to file so we can work with it later on\n",
    "utils.save_to_json('%s.json' % DATASET_NAME, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Explore the dataset (know your data!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load dataset from saved file\n",
    "DATASET_NAME = 'broad'\n",
    "dataset = utils.load_from_json('%s.json' % DATASET_NAME)\n",
    "N = len(dataset[dataset.keys()[0]]) # Number of sounds per class\n",
    "print 'Loaded dataet \"%s\" (%i classes, %i sounds per class)' % (DATASET_NAME, len(dataset.keys()), N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Pick some sounds from each category and show players (Freesound embeds) to listen to them\n",
    "for class_name, sounds in dataset.items():\n",
    "    html = \"<h3>%s</h3>\" % class_name\n",
    "    html += \"<h4>Example sounds:</h4>\"\n",
    "    html += utils.generate_html_with_sound_examples([sound['id'] for sound in sounds][:6])\n",
    "    html += \"<h4>Most commons tags tagcloud:</h4>\"\n",
    "    class_tags = utils.get_all_tags_from_class(class_name, dataset)\n",
    "    html += utils.generate_html_tagcloud(class_tags, N=100, max_px=50, min_px=10, pow_scale=1.2)\n",
    "    html += \"<br>\"\n",
    "    display(HTML(html)) # <- This is pure jupyter notebook AWESOMENESS magic which renders the HTML in the output of the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
